# Traditional NLP

## Supervised Learning Paradigm

![](./img/1.PNG)

    ##Observation(input)
    - xë¡œ ì£¼ë¡œ ì‚¬ìš©
    - ìš°ë¦¬ê°€ ì˜ˆì¸¡í•´ì•¼í•  ë¬´ì–¸ê°€

    #Target(LABEL)
    - observationê³¼ì˜ ì¼ì¹˜ì„±ê¸°ë°˜
    - ì˜ˆì¸¡ë˜ì–´ì•¼ í• ê²ƒ
    - Y

    #Model
    - í•¨ìˆ˜ ë° ìˆ˜í•™ì  í‘œí˜„
    - xë¥¼ í†µí•´ yë¥¼ ì˜ˆì¸¡

    #Parameter
    - modelì˜ íŒŒë¼ë¯¸í„°
    - wë¡œ ì£¼ë¡œ ì‚¬ìš©

    #Predictions
    - ì£¼ì–´ì§„ observation, modelì— ë„£ì–´ targetì„ ì˜ˆì¸¡
    - ğ‘¦í–‡ ìœ¼ë¡œ í‘œí˜„

    #Loss function, â„’(ğ‘¦, ğ‘¦í–‡)
    - targetê³¼ predictionsê³¼ì˜ ë¹„êµ

## One-Hot Representation(C)

    - 0 ë²¡í„°ë¡œ ì‹œì‘í•˜ê³  ìˆëŠ” ê²½ìš° ë²¡í„° í•´ë‹¹ í•­ëª©ì„ 1ë¡œ ì„¤ì •
    - text->numìœ¼ë¡œ ë°”ê¾¸ëŠ” ê°€ì¥ ì›ì´ˆì  ë°©ë²•

## TF Inverse Document Frequency(TF-IDF)(C)

    - fruitê°€ ë‘ë²ˆë‚˜ì™”ê³  ì´ëŠ” topicì´ fruitë¼ê³  ì¶”ì¸¡ê°€ëŠ¥
    - í•˜ì§€ë§Œ topicì•„ ì•„ë‹ˆì—¬ë„ ìì£¼ë‚˜ì˜¤ëŠ” ë‹¨ì–´ê°€ ìˆì„ ìˆ˜ ìˆìŒ(ë°˜ëŒ€ì˜ ê²½ìš°ë„ ì¡´ì¬)
    - ì‚¬ì§„ê³¼ ê°™ì´ penalizeí•˜ëŠ”ê²ƒì´ ìˆìŒ(ì¤‘ìš”í•˜ì§€ ì•Šì€ ë‹¨ì–´ì¸ë° ìì£¼ ë‚˜ì˜¤ëŠ”ê²ƒì„ penaltyë¥¼ ì¤€ë‹¤)

| ![](./img/2.PNG) | ![](./img/3.PNG) |
| ---------------- | ---------------- |

## Word Vectors

    ë¹„ìŠ·í•œ ì˜ë¯¸ì˜ ë‹¨ì–´ëŠ” ë‚´ì ì˜ í¬ê¸°ê°€ í¬ë„ë¡ ì„¤ì •
    ex) motel, hotel

# Text Preprocessing

## Corpus(C)

    text data set
    raw data

## Tokenization(C)

    textë¶„ì„ì˜ ì´ˆê¸° step
    textë¥¼ ì‘ì€ tokenìœ¼ë¡œ ìª¼ê°¬
    spacy, nltkë¥¼ í†µí•œ sentence ìª¼ê°œê¸°

| ![](./img/4.PNG) | ![](./img/5.PNG) |
| ---------------- | ---------------- |

## StopWords(C)

    words= content words+ stopwords
    í¬ê¸° ì˜ë¯¸ê°€ ì—†ëŠ” ë‹¨ì–´ ex) by, about...
    NLP analysisì—ì„œëŠ” ì‚­ì œê°€ í•„ìˆ˜ì ì„

| ![](./img/6.PNG) | ![](./img/7.PNG) |
| ---------------- | ---------------- |

## Stemming(C)

    text ì¼ë°˜í™”
        ex- consultant, consulting, consultantiative.. => consult

## Lemmatization(C)

    contextë¥¼ ê¸°ë°˜í•˜ì—¬ êµ¬ë¶„(stemê³¼ì˜ ì°¨ì´)

| ![](./img/8.PNG) | ![](./img/9.PNG) |
| ---------------- | ---------------- |

## POST tagging(C)

    ë™ì‚¬, ëª…ì‚¬ , í˜•ìš©ì‚¬ ë“±ì„ êµ¬ë¶„
    ë¬¸ì¥ì—ì„œì˜ relationshipì„ ì°¾ìŒ

| ![](./img/10.PNG) | ![](./img/11.PNG) |
| ----------------- | ----------------- |

## Recognizing entities(C)

    sentenceì—ì„œ main thingì„ ì°¾ëŠ”ê²ƒ

![](./img/12.PNG)

## Dependency Parsing(C)

    ë‹¨ì–´ì—ì„œì˜ ê´€ê³„ë¥¼ ì°¾ìŒ

![](./img/19.PNG)

## Word Cloud(C)

    ê°€ì¥ ë¹ˆë²ˆí•˜ê²Œ ë‚˜ì˜¨ ë‹¨ì–´ë¥¼ graphicí™”
    ì£¼ë¡œ ê´‘ê³ ì—ì„œ ì‚¬ìš©ë¨
    ë§ì´ ë‚˜ì˜¬ìˆ˜ë¡ ì‚¬ì´ì¦ˆê°€ í¼

![](./img/18.PNG)

# Text Feature Engineering

## Bag of Words(C)

    text-> numeric vectorë¡œ ë°”ê¾¸ëŠ” ê°€ì¥ ì¸ê¸°ìˆê³  ê°„ë‹¨í•œ ë°©ë²•
    1. vocabulary wordsë¥¼ ìˆ˜ì§‘
    2. ë¹ˆë²ˆë„ ë¶„ì„

## n-gram

![](./img/13.PNG)
ë‹¨ì–´ë¥¼ nê°œë¡œ ë¬¶ì–´ì„œ ë¶„ì„

# Text Similarity(ìœ ì‚¬ë„ ë¹„êµ)

## Jaccard similarity(C)

| ![](./img/14.PNG) | ![](./img/15.PNG) |
| ----------------- | ----------------- |

    ë‘ê°œì˜ setì— ëŒ€í•œ ìœ ì‚¬ë„ ratio

## Cosine similarity(C)

| ![](./img/16.PNG) | ![](./img/17.PNG) |
| ----------------- | ----------------- |

    ì–¼ë§ˆë‚˜ ì„œë¡œ ê´€ë ¨ì´ ìˆëŠ”ì§€ ê³„ì‚°
    bag of words, TF-IDF ë‘˜ë‹¤ ì‚¬ìš© ê°€ëŠ¥
